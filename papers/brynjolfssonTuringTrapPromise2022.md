# The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence

They define the Turing Trap as the idea that because we're so obsessed with developing human level AI (HLAI) to *automate* rather than *augment*, then we're creating a growing class of people who won't be able to contribute anything that couldn't be replaced with HLAI.

> This has created a growing fear that AI and related advances will lead to a burgeoning class of unemployable or “zero marginal product” people.

I think the author makes an interesting point that before, knowledge was compressed and stored into indecipherable brains. Now even though we have the web, it's getting compressed again into LLMs which help to concentrate power once again.

> Rather than specify a task that neither humans nor machines have ever done before, why not ask the research team to design a machine that replicates an existing human capability? Unlike more ambitious goals, replication has an existence proof that such tasks are, in principle, feasible and useful.

For me, this also strikes the biggest chord for my current issues with AI. It's amazing that we're able to get a machine to do things that were previously unimaginable like play chess, but when can they *invent*, when can they *create*?

Even though I see their point about how our taxes currently prioritize automation over augmentation, it's worth noting that "augmentation" can lead to making humans part of the system rather than embracing their unique strengths. Factories might be considered automation, but it also automated the work that people have to do.